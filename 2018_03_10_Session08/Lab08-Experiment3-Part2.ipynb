{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab08-Experiment3-Part2.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"7YqGG5QJ1_93","colab_type":"text"},"cell_type":"markdown","source":["# Foundations of AI & ML\n","## Session 08\n","### Experiment 3 Part 2"]},{"metadata":{"id":"Da6Wi7df1_94","colab_type":"text"},"cell_type":"markdown","source":["### Leave One Out\n","\n","Leave One Out is a special form of Cross-Validation. In this method each sample is used once as a test set while the remaining samples for the training set. A generalization error estimate is obtained by repeating this procedure for each of the training points available, averaging the results.\n","\n","In this experiment we are going to apply LOO on the MNIST dataset and then tune the hyper parameters of MLPClassifier."]},{"metadata":{"id":"FIzcTYBP1_95","colab_type":"text"},"cell_type":"markdown","source":["#### Importing the packages"]},{"metadata":{"id":"fePmyvT21_95","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn import datasets\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import LeaveOneOut"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4lYNHuw11_98","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["## Loading the dataset\n","digits = datasets.load_digits(n_class=10)\n","## storing the data in x\n","X = digits.data\n","## Storing the target data into y\n","y = digits.target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"2MkIGkOP1_9-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":35},"outputId":"67b8ea53-5acb-457a-f9f5-0b94a584a11d","executionInfo":{"status":"ok","timestamp":1527160360702,"user_tz":-330,"elapsed":776,"user":{"displayName":"Amulya Mamindla","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"104611679557974953873"}}},"cell_type":"code","source":["# Creating the object\n","loo = LeaveOneOut()\n","#Returns the number of splitting iterations in the cross-validator\n","loo.get_n_splits(X)\n"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1797"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"jxvLCxX41_-B","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["### hyper parameters\n","# activation\n","a = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n","#solvers\n","s = [\"lbfgs\",\"sgd\",\"adam\"]\n","#learning rate\n","lr = [0.0001,0.001,0.01,0.1]\n","#hidden layers\n","h = [(5,2),(3,2),(6,3),(7,2)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YbgdxKY41_-D","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#function to Create MLP classifier object with hyper parameters\n","def mlp(a,s,h,lr):\n","    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 5000 ,learning_rate = 'constant',learning_rate_init=lr)\n","    return clf \n","#function to calculate the accuracy\n","def accuracy(actual,predicted):\n","    return np.count_nonzero(actual == predicted)*1.0/len(actual)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IeSF1U_11_-F","colab_type":"text"},"cell_type":"markdown","source":["** Exercise 1 ** Predict the values on the trained model using test data and calculate the accuracy"]},{"metadata":{"id":"-xfnlfxH1_-F","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":381},"outputId":"f2b1dc70-3471-4637-cfd3-9644650d233f"},"cell_type":"code","source":["test_accuracy = []\n","train_accuracy = []\n","for i in range(10):\n","    k1 = np.random.randint(0,len(a))\n","    k2 = np.random.randint(0,len(s))\n","    k3 = np.random.randint(0,len(lr))\n","    k4 = np.random.randint(0,len(h))\n","    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n","    #calling the mlp function with random hyper paramters\n","    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n","    tempTrain = 0\n","    tempTest = 0\n","    for train_index, test_index in loo.split(X):\n","    ## Splitting the data into train and test\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test = y[train_index], y[test_index]\n","        ##fit the data into the model\n","        clf.fit(X_train,Y_train)\n","        ##predicting the values on the fitted model\n","        predTrain = clf.predict((X_train))\n","        ##Calculating the train accuracy\n","        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n","        ##predict the values on the fitted model using test data\n","        predTest =clf.predict((X_test))\n","        ##Calculating the test accuracy\n","        tempTest = tempTest + accuracy(Y_test,predTest)\n","    ##Calculating the train accuracy\n","    train_accuracy.append(tempTrain*1.0/1797)\n","    ##Calculating the test accuracy\n","    test_accuracy.append(tempTest*1.0/1797)\n","    print(\"(train,test) accuracy = \",tempTrain*1.0, tempTest*1.0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Hyper-parameters = \n"," activation =  identity \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (7, 2)\n","(train,test) accuracy =  1312.6748329621419 1269.0\n","\n","Hyper-parameters = \n"," activation =  tanh \n"," solver =  adam \n"," learning_rate_init =  0.1 \n"," hidden_layer_sizes =  (6, 3)\n","(train,test) accuracy =  558.8351893095763 567.0\n","\n","Hyper-parameters = \n"," activation =  logistic \n"," solver =  sgd \n"," learning_rate_init =  0.001 \n"," hidden_layer_sizes =  (5, 2)\n"],"name":"stdout"}]},{"metadata":{"id":"SwskQq0X1_-I","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#Plotting the data\n","xx = np.array(range(1,11))\n","plt.bar(xx-0.2,train_accuracy,width=0.2)\n","plt.bar(xx, test_accuracy,width=0.2)\n","plt.legend([\"Train\",\"Test\"])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ALr-tsDK1_-K","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 2** vary the hidden layers, learning rate values  and observe the changes"]},{"metadata":{"id":"lqm74JaD1_-L","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["we "],"execution_count":0,"outputs":[]},{"metadata":{"id":"0zuF7G2Q1_-Q","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"tmagIyD21_-T","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"FuOnh7EU1_-U","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Jt8lUCSb1_-Y","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"-uU2RcaM1_-a","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"0MBe52gh1_-b","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"aCfn7YHc1_-d","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"xsyHWj521_-f","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"f3DiDnL81_-g","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"MNQph6V21_-j","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"hIIkgK251_-l","colab_type":"text"},"cell_type":"markdown","source":["**Solutions**"]},{"metadata":{"id":"CyR4RSm61_-n","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 1 **"]},{"metadata":{"id":"o04BvdaG1_-o","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["predTest = clf.predict((X_test))\n","tempTest = tempTest + accuracy(Y_test,predTest)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yhnbibCV1_-s","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 2 **"]},{"metadata":{"id":"o3eC8SBf1_-s","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["#learning rate\n","lr = [0.0001,0.001,0.01,0.1,0.002,0.2]\n","#hidden layers\n","h = [(5,4),(9,2),(4,8),(7,5)]"],"execution_count":0,"outputs":[]}]}