{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab08-Experiment3-Part2.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"cells":[{"metadata":{"id":"ekINlZtz4lNU","colab_type":"text"},"cell_type":"markdown","source":["# Foundations of AI & ML\n","## Session 08\n","### Experiment 3 Part 2"]},{"metadata":{"id":"js39BFgy4lNV","colab_type":"text"},"cell_type":"markdown","source":["### Leave One Out\n","\n","Leave One Out is a special form of Cross-Validation. In this method each sample is used once as a test set while the remaining samples for the training set. A generalization error estimate is obtained by repeating this procedure for each of the training points available, averaging the results.\n","\n","In this experiment we are going to apply LOO on the MNIST dataset and then tune the hyper parameters of MLPClassifier."]},{"metadata":{"id":"OyScfJRR4lNW","colab_type":"text"},"cell_type":"markdown","source":["#### Importing the packages"]},{"metadata":{"id":"wjdVcQfg4lNW","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","from matplotlib import pyplot as plt\n","from sklearn import datasets\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.model_selection import LeaveOneOut"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PosZzxEt4lNa","colab_type":"code","colab":{}},"cell_type":"code","source":["## Loading the dataset\n","digits = datasets.load_digits(n_class=10)\n","## storing the data in x\n","X = digits.data\n","## Storing the target data into y\n","y = digits.target"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Z_YmV2hg4lNc","colab_type":"code","colab":{},"outputId":"107cdfe4-7e60-4a48-f4b3-b248a0dc25c3"},"cell_type":"code","source":["# Creating the object\n","loo = LeaveOneOut()\n","#Returns the number of splitting iterations in the cross-validator\n","loo.get_n_splits(X)\n"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1797"]},"metadata":{"tags":[]},"execution_count":3}]},{"metadata":{"id":"bP2Pd23w4lNi","colab_type":"code","colab":{}},"cell_type":"code","source":["### hyper parameters\n","# activation\n","a = [\"identity\",\"logistic\",\"tanh\",\"relu\"]\n","#solvers\n","s = [\"lbfgs\",\"sgd\",\"adam\"]\n","#learning rate\n","lr = [0.0001,0.001,0.01,0.1]\n","#hidden layers\n","h = [(5,2),(3,2),(6,3),(7,2)]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AQSNgmsL4lNl","colab_type":"code","colab":{}},"cell_type":"code","source":["#function to Create MLP classifier object with hyper parameters\n","def mlp(a,s,h,lr):\n","    clf = MLPClassifier(activation= a ,solver= s ,hidden_layer_sizes = h,max_iter = 5000 ,learning_rate = 'constant',learning_rate_init=lr)\n","    return clf \n","#function to calculate the accuracy\n","def accuracy(actual,predicted):\n","    return np.count_nonzero(actual == predicted)*1.0/len(actual)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Q-TEA2t34lNn","colab_type":"text"},"cell_type":"markdown","source":["** Exercise 1 ** Predict the values on the trained model using test data and calculate the accuracy"]},{"metadata":{"id":"eif9_JRw4lNo","colab_type":"code","colab":{},"outputId":"99b3f0cb-506e-4246-9201-6df768789d06"},"cell_type":"code","source":["test_accuracy = []\n","train_accuracy = []\n","for i in range(10):\n","    k1 = np.random.randint(0,len(a))\n","    k2 = np.random.randint(0,len(s))\n","    k3 = np.random.randint(0,len(lr))\n","    k4 = np.random.randint(0,len(h))\n","    print(\"\\nHyper-parameters = \\n activation = \", a[k1],    \"\\n solver = \", s[k2], \"\\n learning_rate_init = \", lr[k3],         \"\\n hidden_layer_sizes = \", h[k4])\n","    #calling the mlp function with random hyper paramters\n","    clf = mlp(a[k1],s[k2],h[k4],lr[k3])\n","    tempTrain = 0\n","    tempTest = 0\n","    for train_index, test_index in loo.split(X):\n","    ## Splitting the data into train and test\n","        X_train, X_test = X[train_index], X[test_index]\n","        Y_train, Y_test = y[train_index], y[test_index]\n","        ##fit the data into the model\n","        clf.fit(X_train,Y_train)\n","        ##predicting the values on the fitted model\n","        predTrain = clf.predict((X_train))\n","        ##Calculating the train accuracy\n","        tempTrain = tempTrain + accuracy(Y_train,predTrain)\n","        ##predict the values on the fitted model using test data\n","        predTest = clf.predict((X_test))\n","        ##Calculating the test accuracy\n","        tempTest = tempTest + accuracy(Y_test,predTest)\n","    ##Calculating the train accuracy\n","    train_accuracy.append(tempTrain*1.0/1797)\n","    ##Calculating the test accuracy\n","    test_accuracy.append(tempTest*1.0/1797)\n","    print(\"(train,test) accuracy = \",tempTrain*1.0, tempTest*1.0)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Hyper-parameters = \n"," activation =  logistic \n"," solver =  adam \n"," learning_rate_init =  0.0001 \n"," hidden_layer_sizes =  (6, 3)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:564: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (5000) reached and the optimization hasn't converged yet.\n","  % self.max_iter, ConvergenceWarning)\n"],"name":"stderr"}]},{"metadata":{"id":"MhsXHWRr4lNs","colab_type":"code","colab":{}},"cell_type":"code","source":["#Plotting the data\n","xx = np.array(range(1,11))\n","plt.bar(xx-0.2,train_accuracy,width=0.2)\n","plt.bar(xx, test_accuracy,width=0.2)\n","plt.legend([\"Train\",\"Test\"])\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BPPcGRwB4lNt","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 2** vary the hidden layers, learning rate values  and observe the changes"]},{"metadata":{"id":"9a63TdKg4lNv","colab_type":"code","colab":{}},"cell_type":"code","source":["we "],"execution_count":0,"outputs":[]},{"metadata":{"id":"WzqOwOPe4lNy","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"KWL-Dxhw4lN0","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"uNrXGWff4lN1","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"qN0CMGDL4lN3","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"dq2_d7le4lN6","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"4YF7kB8y4lN-","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"5iR5NXn64lOC","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"vzoe91NC4lOF","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"l0aoL5KB4lOJ","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"2tGfFb9B4lOL","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"Pb4iudxh4lOO","colab_type":"text"},"cell_type":"markdown","source":["**Solutions**"]},{"metadata":{"id":"MzFL7E264lOP","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 1 **"]},{"metadata":{"id":"M0sfRZg14lOQ","colab_type":"code","colab":{}},"cell_type":"code","source":["predTest = clf.predict((X_test))\n","tempTest = tempTest + accuracy(Y_test,predTest)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9BK3tgzk4lOU","colab_type":"text"},"cell_type":"markdown","source":["**Exercise 2 **"]},{"metadata":{"id":"PkufOIB74lOU","colab_type":"code","colab":{}},"cell_type":"code","source":["#learning rate\n","lr = [0.0001,0.001,0.01,0.1,0.002,0.2]\n","#hidden layers\n","h = [(5,4),(9,2),(4,8),(7,5)]"],"execution_count":0,"outputs":[]}]}